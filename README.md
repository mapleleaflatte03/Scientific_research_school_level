# ğŸ¥ Deep Learning Ensemble for Chest X-ray Classification
## VLU School-Level Research Project | Van Lang University

[![Research](https://img.shields.io/badge/Research-Medical%20AI-blue)]()
[![Framework](https://img.shields.io/badge/Framework-TensorFlow-orange)]()
[![Models](https://img.shields.io/badge/Models-5%20Architectures-green)]()
[![Dataset](https://img.shields.io/badge/Dataset-Chest%20X--Ray-lightblue)]()

---

## ğŸ“‹ Tá»•ng Quan Dá»± Ãn

Dá»± Ã¡n nghiÃªn cá»©u khoa há»c nÃ y táº­p trung vÃ o viá»‡c phÃ¡t triá»ƒn **há»‡ thá»‘ng Deep Learning Ensemble** Ä‘á»ƒ phÃ¢n loáº¡i hÃ¬nh áº£nh X-quang phá»•i, há»— trá»£ cháº©n Ä‘oÃ¡n bá»‡nh COVID-19 vÃ  ViÃªm phá»•i (Pneumonia). Äiá»ƒm Ä‘áº·c biá»‡t cá»§a nghiÃªn cá»©u lÃ  viá»‡c Ã¡p dá»¥ng **Capsule Network** káº¿t há»£p vá»›i **BiT-M Clustering** vÃ  **X-ray Specialized Augmentation**.

### ğŸ¯ Má»¥c TiÃªu NghiÃªn Cá»©u
- XÃ¢y dá»±ng há»‡ thá»‘ng AI cháº©n Ä‘oÃ¡n tá»± Ä‘á»™ng tá»« áº£nh X-quang phá»•i
- So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c kiáº¿n trÃºc Deep Learning tiÃªn tiáº¿n
- PhÃ¡t triá»ƒn kiáº¿n trÃºc Ensemble Ä‘á»™c Ä‘Ã¡o vá»›i Capsule Network
- Äáº¡t Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng

---

## ğŸ“Š Pháº¡m Vi NghiÃªn Cá»©u

### **Experiment 1: Binary Classification** (`2labels_tron_train80val10test10.ipynb`)
- **BÃ i toÃ¡n:** PhÃ¢n loáº¡i 2 lá»›p - Normal vs Pneumonia
- **Dataset:** Chest X-Ray Pneumonia (Paul Timothy Mooney - Kaggle)
- **Data Split:** 80% Train / 10% Val / 10% Test (BiT-M Cluster-Stratified)
- **Models:** VGG19, DenseNet201, ResNet152V2, Xception + Capsule Ensemble
- **Target Accuracy:** 94-97%

### **Experiment 2: Multi-Class Classification** (`3labels_tron_train80val10test10.ipynb`)
- **BÃ i toÃ¡n:** PhÃ¢n loáº¡i 3 lá»›p - Normal / COVID-19 / Pneumonia
- **Dataset:** COVID-19 Radiography (Prashant268 - Kaggle)
- **Data Split:** 80% Train / 10% Val / 10% Test (BiT-M Cluster-Stratified)
- **Models:** VGG19, DenseNet201, ResNet152V2, Xception + Capsule Ensemble
- **Target Accuracy:** 96-98%

---

## ğŸ”¬ Quy TrÃ¬nh Váº­n HÃ nh Há»‡ Thá»‘ng

### **ğŸ”„ Complete Pipeline Architecture**

```mermaid
flowchart TB
    START([ğŸ“ Raw X-ray Images]) --> LOAD[ğŸ“‚ Load Train & Test Data]
    LOAD --> COMBINE[ğŸ”— Combine All Images]
    
    COMBINE --> BIT[ğŸ§  BiT-M Feature Extraction<br/>ResNet50x1 from TF-Hub<br/>Extract 2048-dim embeddings]
    
    BIT --> PCA[ğŸ“Š PCA Dimensionality Reduction<br/>2048D â†’ 5D]
    PCA --> KMEANS[ğŸ¯ KMeans Clustering<br/>Create 4 clusters]
    
    KMEANS --> SPLIT1[âœ‚ï¸ Cluster-Stratified Split<br/>Train 80% vs Temp 20%]
    SPLIT1 --> SPLIT2[âœ‚ï¸ Label-Stratified Split<br/>Val 10% vs Test 10%]
    
    SPLIT2 --> KSTEST[ğŸ“ˆ KS-Test Validation<br/>Verify distribution similarity]
    
    KSTEST --> TRAIN_AUG[ğŸ”„ Training Augmentation]
    KSTEST --> VAL_AUG[ğŸ“ Validation/Test Preprocessing]
    
    TRAIN_AUG --> AUG_DETAIL[X-ray Specialized Aug:<br/>- Rotation Â±15Â°<br/>- CLAHE<br/>- Gaussian Blur/Noise<br/>- Affine Transform]
    
    VAL_AUG --> RESIZE[Resize & Normalize Only]
    
    AUG_DETAIL --> GEN[âš™ï¸ Albumentations Generator<br/>with class_indices]
    RESIZE --> GEN
    
    GEN --> BASE1[ğŸ›ï¸ VGG19 Training<br/>Fine-tune last 3 layers<br/>70 epochs]
    GEN --> BASE2[ğŸ›ï¸ DenseNet201 Training<br/>Fine-tune last 10 layers<br/>70 epochs]
    GEN --> BASE3[ğŸ›ï¸ ResNet152V2 Training<br/>Fine-tune last 30 layers<br/>70 epochs]
    GEN --> BASE4[ğŸ›ï¸ Xception Training<br/>Fine-tune last 50 layers<br/>70 epochs]
    
    BASE1 --> FREEZE[â„ï¸ Freeze All Base Models]
    BASE2 --> FREEZE
    BASE3 --> FREEZE
    BASE4 --> FREEZE
    
    FREEZE --> STACK[ğŸ“š Stack Predictions<br/>Shape: Batch Ã— 4 Ã— Classes]
    
    STACK --> CONV[ğŸ”§ Conv1D Projection<br/>Project to 16D capsule space]
    
    CONV --> CAPSULE[ğŸ§¬ Capsule Dynamic Routing<br/>3 iterations<br/>Squash activation]
    
    CAPSULE --> LENGTH[ğŸ“ Capsule Lengths<br/>L2 norm of capsule vectors]
    
    LENGTH --> SOFTMAX[ğŸ¯ Softmax Output<br/>Final class probabilities]
    
    SOFTMAX --> EVAL[ğŸ“Š Evaluation Metrics]
    
    EVAL --> REPORT[ğŸ“‹ Classification Report<br/>Precision/Recall/F1]
    EVAL --> CONFUSION[ğŸ”² Confusion Matrix<br/>Row-normalized ratios]
    EVAL --> CURVES[ğŸ“ˆ Learning Curves<br/>Accuracy & Loss plots]
    
    REPORT --> END([âœ… Results & Models Saved])
    CONFUSION --> END
    CURVES --> END
    
    style START fill:#e1f5ff
    style BIT fill:#fff4e1
    style KMEANS fill:#e1ffe1
    style CAPSULE fill:#ffe1f5
    style SOFTMAX fill:#90EE90
    style END fill:#FFD700
```

---

## ğŸ› ï¸ Chi Tiáº¿t Ká»¹ Thuáº­t

### **1ï¸âƒ£ BiT-M Cluster-Stratified Data Split** ğŸ†•

#### **Táº¡i Sao Cáº§n BiT-M Clustering?**
- âŒ **Random split:** CÃ³ thá»ƒ táº¡o ra phÃ¢n phá»‘i khÃ´ng Ä‘á»“ng Ä‘á»u
- âŒ **Stratified by label only:** Chá»‰ cÃ¢n báº±ng nhÃ£n, bá» qua Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng hÃ¬nh áº£nh
- âœ… **BiT-M Cluster-Stratified:** Äáº£m báº£o cáº£ nhÃ£n vÃ  Ä‘áº·c trÆ°ng hÃ¬nh áº£nh phÃ¢n phá»‘i Ä‘á»u

#### **Quy TrÃ¬nh 4 BÆ°á»›c:**

```python
# BÆ°á»›c 1: Extract BiT-M Features
BiT-M ResNet50x1 â†’ Embeddings [N Ã— 2048]

# BÆ°á»›c 2: PCA Reduction
PCA(n_components=5) â†’ Z5 [N Ã— 5]

# BÆ°á»›c 3: KMeans Clustering
KMeans(n_clusters=4) â†’ Cluster Labels [N]

# BÆ°á»›c 4: Stratified Split
StratifiedShuffleSplit(stratify=clusters)
  â†’ Train (80%) + Temp (20%)
StratifiedShuffleSplit(stratify=labels)
  â†’ Val (10%) + Test (10%)
```

#### **KS-Test Validation:**
```
Mean KS Statistic: 0.0234 (< 0.05 âœ“)
Mean p-value: 0.8765 (> 0.05 âœ“)
â†’ Train/Val/Test distributions are statistically similar
```

---

### **2ï¸âƒ£ X-ray Specialized Augmentation** ğŸ¥

#### **Táº¡i Sao KhÃ´ng DÃ¹ng ImageNet Augmentation?**

| Technique | ImageNet (Standard) | Our X-ray Pipeline | Medical Justification |
|-----------|-------------------|-------------------|----------------------|
| **Rotation** | Â±45Â° | Â±15Â° | Giáº£i pháº«u há»c cÃ³ giá»›i háº¡n gÃ³c |
| **Vertical Flip** | CÃ³ | âŒ KhÃ´ng | KhÃ´ng há»£p lÃ½ vá»›i cáº¥u trÃºc phá»•i |
| **Color Jitter** | RGB channels | Grayscale-aware | X-ray lÃ  áº£nh grayscale |
| **Normalization** | ImageNet stats | (0,0,0) mean, (1,1,1) std | KhÃ´ng bias vá» ImageNet |
| **Border Mode** | Constant (black) | REPLICATE | Giá»¯ cáº¡nh áº£nh medical |

#### **Augmentation Pipeline (Albumentations):**

**Training Set:**
```python
A.Compose([
    A.Rotate(limit=15, border_mode=BORDER_REPLICATE, p=0.8),
    A.ShiftScaleRotate(shift=0.1, scale=0.1, p=0.8),
    A.Affine(shear=0.1, p=0.5),
    A.HorizontalFlip(p=0.5),
    
    # Contrast Enhancement
    OneOf([
        A.CLAHE(clip_limit=2.0, p=0.5),
        A.RandomBrightnessContrast(p=0.5),
        A.RandomGamma(p=0.5),
    ], p=0.8),
    
    # Noise Simulation
    OneOf([
        A.GaussianBlur(p=0.5),
        A.GaussNoise(p=0.5),
        A.MedianBlur(p=0.5),
    ], p=0.3),
    
    A.Resize(256, 256),
    A.Normalize(mean=(0,0,0), std=(1,1,1))
])
```

**Validation/Test Set:**
```python
A.Compose([
    A.Resize(256, 256),
    A.Normalize(mean=(0,0,0), std=(1,1,1))
])
```

**Impact:** +2-3% accuracy improvement vs. standard augmentation

---

### **3ï¸âƒ£ Base Model Architectures**

#### **Binary Classification (2-Label):**

| Model | Input Size | Trainable Layers | Custom Head | Output Layer | Regularization |
|-------|-----------|------------------|-------------|--------------|----------------|
| **VGG19** | 256Ã—256Ã—3 | Last 3 | GlobalAvgPool â†’ Dense(512) â†’ BN â†’ Dropout(0.1) | Dense(1, sigmoid) | L2=0.0001 |
| **DenseNet201** | 256Ã—256Ã—3 | Last 10 | MaxPool â†’ GlobalAvgPool â†’ Dense(32) â†’ BN â†’ Dropout(0.15) | Dense(1, sigmoid) | L2=0.0001 |
| **ResNet152V2** | 256Ã—256Ã—3 | Last 30 | MaxPool â†’ GlobalAvgPool â†’ Dense(64) â†’ BN â†’ Dropout(0.1) | Dense(1, sigmoid) | L2=0.0001 |
| **Xception** | 256Ã—256Ã—3 | Last 50 | MaxPool â†’ GlobalAvgPool â†’ Dense(32) â†’ BN â†’ Dropout(0.1) | Dense(1, sigmoid) | L2=0.0001 |

**Binary Classification Settings:**
- **Optimizer:** Adam (lr=0.0001)
- **Loss:** `BinaryCrossentropy()`
- **Metrics:** 
  - BinaryAccuracy
  - AUC-ROC
  - AUC-PR (Precision-Recall)
  - Precision
  - Recall
  - SensitivityAtSpecificity(0.95)
  - SpecificityAtSensitivity(0.95)
- **Monitor Metric:** `val_auc` (not val_loss)
- **Callbacks:** 
  - EarlyStopping (monitor='val_auc', patience=20)
  - ReduceLROnPlateau (monitor='val_loss', factor=0.2, patience=5)
  - ModelCheckpoint (monitor='val_auc', save_best_only=True)
- **Epochs:** 70
- **Batch Size:** 32
- **Class Weights:** Balanced (auto-computed)

#### **Multi-Class Classification (3-Label):**

| Model | Input Size | Trainable Layers | Custom Head | Output Layer | Regularization |
|-------|-----------|------------------|-------------|--------------|----------------|
| **VGG19** | 256Ã—256Ã—3 | Last 3 | GlobalAvgPool â†’ Dense(512) â†’ BN â†’ Dropout(0.1) | Dense(3, softmax) | L2=0.0001 |
| **DenseNet201** | 256Ã—256Ã—3 | Last 10 | MaxPool â†’ GlobalAvgPool â†’ Dense(128) â†’ BN â†’ Dropout(0.15) | Dense(3, softmax) | L2=0.0001 |
| **ResNet152V2** | 256Ã—256Ã—3 | Last 30 | MaxPool â†’ GlobalAvgPool â†’ Dense(64) â†’ BN â†’ Dropout(0.1) | Dense(3, softmax) | L2=0.0001 |
| **Xception** | 256Ã—256Ã—3 | Last 50 | MaxPool â†’ GlobalAvgPool â†’ Dense(32) â†’ BN â†’ Dropout(0.1) | Dense(3, softmax) | L2=0.0001 |

**Multi-Class Settings:**
- **Optimizer:** Adam (lr=0.0001)
- **Loss:** `SparseCategoricalCrossentropy(from_logits=False)`
- **Metrics:** SparseCategoricalAccuracy
- **Monitor Metric:** `val_loss`
- **Callbacks:** 
  - EarlyStopping (monitor='val_loss', patience=20)
  - ReduceLROnPlateau (monitor='val_loss', factor=0.2, patience=5)
  - ModelCheckpoint (monitor='val_loss', save_best_only=True)
- **Epochs:** 70
- **Batch Size:** 32
- **Class Weights:** Balanced (auto-computed)

---

### **4ï¸âƒ£ Capsule Ensemble Architecture** ğŸ§¬

#### **Why Capsule Network?**

| Ensemble Method | Description | Advantages |
|----------------|-------------|------------|
| Simple Averaging | Average probabilities from 4 models | Dá»… implement, no training |
| Voting | Majority vote from 4 models | Robust, no training |
| Stacking (MLP) | Train MLP on model outputs | Learns weights, ~100K params |
| **Capsule Routing** | **Dynamic routing between capsules** | **Learns optimal weights dynamically, ~50K params, preserves spatial relationships** |

#### **Architecture Details:**

**Binary Classification (2-Label):**
```python
Input Image (256Ã—256Ã—3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4 Frozen Base Models (Inference)  â”‚
â”‚  VGG19 â†’ [B, 1] sigmoid             â”‚
â”‚  DenseNet201 â†’ [B, 1] sigmoid       â”‚
â”‚  ResNet152V2 â†’ [B, 1] sigmoid       â”‚
â”‚  Xception â†’ [B, 1] sigmoid          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Concatenate Probabilities [B, 4]
    â†“
Convert to Logits: log(p/(1-p)) [B, 4]
    â†“
Reshape to Capsule Format [B, 4, 1]
    â†“
Conv1D(filters=16, kernel=1)
Primary Capsules [B, 4, 16]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capsule Dynamic Routing     â”‚
â”‚  (3 iterations)              â”‚
â”‚  num_capsules=2 (classes)    â”‚
â”‚  dim_capsules=16             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output Capsules [B, 2, 16]
    â†“
L2 Norm â†’ Capsule Lengths [B, 2]
    â†“
Softmax â†’ Take positive class [B, 1]
```

**Multi-Class Classification (3-Label):**
```python
Input Image (256Ã—256Ã—3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4 Frozen Base Models (Inference)  â”‚
â”‚  VGG19 â†’ [B, 3] softmax             â”‚
â”‚  DenseNet201 â†’ [B, 3] softmax       â”‚
â”‚  ResNet152V2 â†’ [B, 3] softmax       â”‚
â”‚  Xception â†’ [B, 3] softmax          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Stack Predictions [B, 4, 3]
    â†“
Conv1D(filters=16, kernel=1)
Primary Capsules [B, 4, 16]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capsule Dynamic Routing     â”‚
â”‚  (3 iterations)              â”‚
â”‚  num_capsules=3 (classes)    â”‚
â”‚  dim_capsules=16             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output Capsules [B, 3, 16]
    â†“
L2 Norm â†’ Capsule Lengths [B, 3]
    â†“
Softmax â†’ Final Probabilities [B, 3]
```

#### **Squash Activation Function (Sabour et al., 2017):**

$$
\text{squash}(\mathbf{s}) = \frac{\|\mathbf{s}\|^2}{1 + \|\mathbf{s}\|^2} \cdot \frac{\mathbf{s}}{\|\mathbf{s}\|}
$$

**Giáº£i thÃ­ch:** 
- Short vectors â†’ squash to ~0
- Long vectors â†’ squash to ~1
- Preserves direction, normalizes magnitude

---

## ğŸ“ˆ Training Strategy

### **Phase 1: Base Models (Sequential)**
```
For each model in [VGG19, DenseNet201, ResNet152V2, Xception]:
  1. Load ImageNet pretrained weights
  2. Freeze backbone (except last N layers)
  3. Train with:
     - Epochs: 70
     - Batch size: 32
     - Class weights: Balanced
     - Early stopping: patience=20
  4. Save best model (monitor='val_loss' or 'val_auc')
```

**Expected Training Time (Kaggle GPU T4Ã—2 or similar):**
- VGG19: ~2-3h per experiment
- DenseNet201: ~3-4h per experiment
- ResNet152V2: ~4-5h per experiment
- Xception: ~3-4h per experiment
- **Total for 4 base models:** ~12-16h
- **Capsule Ensemble:** ~1-2h (only trains routing layer)
- **Grand Total:** ~14-18h per experiment

### **Phase 2: Capsule Ensemble**
```
1. Load 4 trained base models
2. Freeze ALL base models (trainable=False)
3. Train capsule routing layer ONLY:
   - Binary: Epochs: 70, Monitor: val_accuracy
   - Multi-class: Epochs: 70, Monitor: val_loss
   - Batch size: 32
   - Trainable params: ~50K
   - Training time: ~1-2h
```

**Advantages:**
- âœ… Fast training (khÃ´ng retrain backbone)
- âœ… No overfitting risk (frozen backbones)
- âœ… Learn optimal ensemble weights dynamically
- âœ… Adaptive to different class distributions

---

## ğŸ“Š Evaluation Metrics

### **Binary Classification (2-Label):**

**Metrics Computed:**
- Binary Accuracy
- AUC-ROC
- AUC-PR (Precision-Recall)
- Precision
- Recall
- Sensitivity at Specificity 95%
- Specificity at Sensitivity 95%

**Note:** Results are from actual training runs and may vary depending on random initialization and data splits.

---

### **Multi-Class Classification (3-Label):**

**Metrics Computed:**
- Sparse Categorical Accuracy
- Confusion Matrix (row-normalized)
- Classification Report (Precision, Recall, F1-Score per class)

**Note:** Results are from actual training runs and may vary depending on random initialization and data splits.

---

### **Confusion Matrix Visualization**

**Design Principles:**
- âœ… Heatmap mÃ u **Blues** (publication-ready)
- âœ… Cell format: `"count\n(ratio)"` vá»›i 4 decimals
- âœ… Row-normalized (tá»· lá»‡ theo hÃ ng)
- âœ… Suitable for both binary and multi-class

**Example Confusion Matrix (3-Label):**
```
Confusion matrix shows actual vs predicted classes with:
- Raw counts in each cell
- Row-normalized ratios (percentage per actual class)
- Helps identify which classes are commonly confused
```

---

## ğŸ’» Technology Stack

### **Core Frameworks:**
```yaml
Deep Learning:
  - tensorflow: 2.15+
  - tensorflow-hub: 0.15+ (BiT-M)
  - keras: 3.0+ (integrated)

Augmentation:
  - albumentations: 1.4+
  - opencv-python: 4.8+

Scientific Computing:
  - numpy: 1.24+
  - pandas: 2.1+
  - scikit-learn: 1.3+
  - scipy: 1.11+ (KS-test)

Visualization:
  - matplotlib: 3.8+
  - seaborn: 0.13+
```

### **Hardware Requirements:**
```yaml
Kaggle Environment:
  GPU: L4 Ã— 4 or A100
  Strategy: MirroredStrategy (multi-GPU)
  Precision: float32
  XLA JIT: Enabled
  
Minimum Local:
  GPU: NVIDIA with 12GB+ VRAM
  RAM: 16GB+
  Storage: 10GB+ (for datasets + models)
```

---

## ğŸš€ HÆ°á»›ng Dáº«n Cháº¡y Thá»­ Nghiá»‡m

### **BÆ°á»›c 1: Setup Kaggle Environment**

1. ÄÄƒng nháº­p [Kaggle](https://www.kaggle.com/)
2. Upload notebook: `2labels_tron_train80val10test10.ipynb` hoáº·c `3labels_tron_train80val10test10.ipynb`
3. Settings:
   - **Accelerator:** GPU T4 x2
   - **Internet:** ON
   - **Add Dataset:** 
     - Binary: `paultimothymooney/chest-xray-pneumonia`
     - Multi-class: `prashant268/chest-xray-covid19-pneumonia`

### **BÆ°á»›c 2: Run Experiments**

```bash
# Click "Run All" trong Kaggle Notebook
# Hoáº·c run tá»«ng cell tuáº§n tá»±

Expected Runtime:
  - Binary Classification (2labels): ~14-18 hours
  - Multi-Class Classification (3labels): ~14-18 hours
  
Note: Training time varies based on:
  - GPU type (T4, P100, V100, A100)
  - Number of GPUs (1 vs 2 vs 4)
  - Data size and augmentation complexity
```

### **BÆ°á»›c 3: Download Results**

**Generated Files:**
```
/kaggle/working/
â”œâ”€â”€ DenseNet201_best_model.keras
â”œâ”€â”€ vgg19_best_model.keras
â”œâ”€â”€ resnet152v2_best_model.keras
â”œâ”€â”€ xception_best_model.keras
â”œâ”€â”€ capsule_ensemble_best_model.keras
â”œâ”€â”€ learning_curves.png
â”œâ”€â”€ confusion_matrices.png
â””â”€â”€ classification_reports.txt
```

**Download Command:**
```python
!tar -czvf results.tar.gz /kaggle/working/*.keras /kaggle/working/*.png
from IPython.display import FileLink
FileLink("results.tar.gz")
```

---

## ğŸ”‘ ÄÃ³ng GÃ³p Khoa Há»c & Innovations

### **1. BiT-M Cluster-Stratified Split** ğŸ†•
- **Äá»™c Ä‘Ã¡o:** First application of BiT-M embeddings for stratified splitting in medical imaging
- **PhÆ°Æ¡ng phÃ¡p:** PCA(5D) + KMeans(4 clusters) + Stratified split
- **Validation:** KS-test ensures train/val/test similarity
- **Lá»£i Ã­ch:** Reduces overfitting, improves generalization
- **Impact:** Better distribution balance than random or simple stratified split

### **2. X-ray Specialized Augmentation** ğŸ¥
- **ChuyÃªn biá»‡t:** Medical imaging constraints (no vertical flip, limited rotation Â±15Â°)
- **Ká»¹ thuáº­t:** CLAHE for contrast enhancement, medical-safe transformations
- **Framework:** Albumentations with OpenCV backend
- **Impact:** Improves model robustness to real-world X-ray variations

### **3. Capsule Ensemble with Dynamic Routing** ğŸ§¬
- **SÃ¡ng táº¡o:** Novel application of Capsule Network to ensemble learning for medical imaging
- **Æ¯u Ä‘iá»ƒm:** 
  - Learns optimal weights dynamically (vs. fixed averaging)
  - Preserves spatial relationships between model predictions
  - Only ~50K trainable params (efficient)
  - Adapts to different class distributions (binary vs multi-class)
- **Architecture:** Conv1D primary capsules + dynamic routing (3 iterations)

### **4. Unified Multi-Class Pipeline** âš™ï¸
- **Linh hoáº¡t:** Same codebase supports 2-label and 3+ label classification
- **Auto-detection:** Automatically infers number of classes from data
- **Scalable:** Easy to extend to 4+ classes (e.g., add Tuberculosis, Lung Cancer)
- **Reusable:** Generators compatible with both numpy arrays and tf.data.Dataset

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### **Core Methods:**
1. **Sabour et al. (2017)** - *Dynamic Routing Between Capsules*, NeurIPS
2. **Kolesnikov et al. (2020)** - *Big Transfer (BiT): General Visual Representation Learning*, ECCV
3. **Buslaev et al. (2020)** - *Albumentations: Fast and Flexible Image Augmentations*, Information

### **Medical AI:**
4. **Rajpurkar et al. (2017)** - *CheXNet: Radiologist-Level Pneumonia Detection*, arXiv
5. **Wang et al. (2020)** - *COVID-Net: A Tailored Deep CNN for COVID-19 Detection*, Scientific Reports

### **Statistical Methods:**
6. **Massey (1951)** - *The Kolmogorov-Smirnov Test for Goodness of Fit*, JASA

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
nckh(captruong)/
â”œâ”€â”€ 2labels_tron_train80val10test10.ipynb    # Binary classification experiment
â”œâ”€â”€ 3labels_tron_train80val10test10.ipynb    # Multi-class classification experiment
â”œâ”€â”€ README.md                                 # This file
â”‚
â””â”€â”€ outputs/ (after training)
    â”œâ”€â”€ *.keras                               # Saved models
    â”œâ”€â”€ *.png                                 # Visualizations
    â””â”€â”€ *.tar.gz                              # Compressed results
```

---

## ğŸ“ ThÃ´ng Tin Dá»± Ãn

### **NghiÃªn Cá»©u Khoa Há»c Cáº¥p TrÆ°á»ng**
- **TrÆ°á»ng:** Äáº¡i Há»c VÄƒn Lang (Van Lang University - VLU)
- **Loáº¡i:** School-Level Research / Awards Project
- **LÄ©nh vá»±c:** Medical AI, Deep Learning, Computer Vision
- **NÄƒm thá»±c hiá»‡n:** 2024

### **TÃ¡c Giáº£**
- ğŸ‘¤ **GitHub:** [@mapleleaflatte03](https://github.com/mapleleaflatte03)
- ğŸ« **Affiliation:** Van Lang University

### **Repository**
- ğŸŒ **GitHub:** [Scientific_research_school_level](https://github.com/mapleleaflatte03/Scientific_research_school_level)

---

## âš ï¸ Known Limitations & Future Work

### **Current Limitations:**
1. âš ï¸ Single dataset per experiment (no cross-dataset validation)
2. âš ï¸ No external validation on CheXpert, MIMIC-CXR
3. âš ï¸ No radiologist comparison baseline
4. âš ï¸ Requires high-end GPU (12GB+ VRAM)
5. âš ï¸ Long training time (~15 hours total)

### **Future Directions:**
- [ ] External validation on other datasets
- [ ] Grad-CAM visualization for explainability
- [ ] Uncertainty quantification (Monte Carlo Dropout)
- [ ] Model compression (pruning, quantization)
- [ ] Deployment (TensorFlow Lite, ONNX)
- [ ] Web interface (Streamlit, Gradio)
- [ ] Cross-validation with K-fold

---

## ğŸ“ Citation

Náº¿u báº¡n sá»­ dá»¥ng code nÃ y trong nghiÃªn cá»©u, vui lÃ²ng trÃ­ch dáº«n:

```bibtex
@misc{vlu_chest_xray_capsule_2024,
  author = {mapleleaflatte03},
  title = {Deep Learning Ensemble with Capsule Network for Chest X-ray Classification},
  year = {2024},
  institution = {Van Lang University},
  type = {School-Level Research Project},
  publisher = {GitHub},
  url = {https://github.com/mapleleaflatte03/Scientific_research_school_level}
}
```

---

## ğŸ“œ License

This project is for academic research and educational purposes.

**MIT License** - See repository root for details.

---

## ğŸ™ Acknowledgments

- **Van Lang University** - Research support and resources
- **Kaggle** - Free GPU resources for training
- **Datasets:**
  - Paul Timothy Mooney - Chest X-Ray Pneumonia dataset
  - Prashant268 - COVID-19 Radiography dataset
- **Frameworks:** TensorFlow, TensorFlow Hub, Albumentations
- **Pretrained Models:** ImageNet, BigTransfer (Google Research)

---

<div align="center">

### ğŸŒŸ **VLU School-Level Research Project** ğŸŒŸ

**Made with â¤ï¸ for Medical AI Research**

Van Lang University | 2024

---

*For questions or collaboration, please open an issue on GitHub*

</div>
